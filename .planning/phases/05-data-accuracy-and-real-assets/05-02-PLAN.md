---
phase: 05-data-accuracy-and-real-assets
plan: 02
type: execute
wave: 2
depends_on:
  - 05-01
files_modified:
  - scripts/scraped-season-records.json
  - scripts/scraped-top-performers-batting.json
  - scripts/scraped-top-performers-bowling.json
autonomous: false
requirements:
  - DATA-01
  - DATA-02

must_haves:
  truths:
    - "Both scraping scripts have been executed and produced JSON output files"
    - "User has reviewed the raw scraped JSON and confirmed which values are correct"
    - "Known data errors are identified: 2021 position=6 should be 2, 2025 season missing, Sunil Narine runs 3500 is wrong, Robin Uthappa runs 3145 is wrong"
  artifacts:
    - path: "scripts/scraped-season-records.json"
      provides: "Raw scraped KKR season records from iplt20.com"
      exports: []
    - path: "scripts/scraped-top-performers-batting.json"
      provides: "Raw scraped KKR batting stats from ESPNcricinfo"
      exports: []
    - path: "scripts/scraped-top-performers-bowling.json"
      provides: "Raw scraped KKR bowling stats from ESPNcricinfo"
      exports: []
  key_links:
    - from: "scraped JSON files"
      to: "human decision"
      via: "checkpoint:human-verify"
      pattern: "manual review"
---

<objective>
Run the two scraping scripts created in Plan 01, then pause for human review of the raw JSON output before any src/data changes. This is a deliberate gate — scraped data from live sports sites can be incomplete or malformed, and human verification against Wikipedia is required before applying corrections.

Purpose: DATA-01 and DATA-02 require verified accuracy. The verify-then-apply pattern prevents bad data from entering stats.ts.
Output: Populated JSON files in scripts/ that have been human-verified. Plan 04 will use this verified data to update stats.ts.
</objective>

<execution_context>
@/Users/mithra_sundaram/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mithra_sundaram/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-data-accuracy-and-real-assets/05-01-SUMMARY.md

<interfaces>
<!-- Known data errors requiring correction (from research) -->

Season records — confirmed errors:
- 2021: current position=6 is WRONG. KKR were runners-up. Correct: position=2, wins ~7, losses ~7 (reach final)
- 2025: MISSING entirely. KKR finished 8th. Correct: ~5 wins, ~9 losses, noResult=0, position=8, title=false

Top performers — confirmed errors:
- Sunil Narine runs: 3500 (WRONG). Actual KKR runs: ~1507 total IPL runs (check scraped data carefully — may be career not KKR-only)
- Robin Uthappa runs: 3145 (WRONG). Actual KKR runs: ~2649
- Gautam Gambhir: currently 2982 (possibly wrong). Verified range: 3035-3345 KKR runs — scraping should clarify
- If ESPNcricinfo was blocked, fallback source: https://en.wikipedia.org/wiki/Kolkata_Knight_Riders#Records_and_statistics
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run both scraping scripts and verify output files exist</name>
  <files>scripts/scraped-season-records.json, scripts/scraped-top-performers-batting.json, scripts/scraped-top-performers-bowling.json</files>
  <action>
Run both scraping scripts from the project root. The scripts are plain Node.js — no compilation needed.

```bash
cd /Users/mithra_sundaram/Desktop/code/AI/projects/team_site
node scripts/scrape-season-records.js
node scripts/scrape-top-performers.js
```

After each script runs:
1. Check the exit code (should be 0)
2. Verify the output JSON file was created
3. Log the first 5 entries of each JSON file to console for quick sanity check

If scrape-season-records.js produces an empty array or fewer than 10 rows, the page structure likely changed. In that case:
- Set page source fallback: navigate to `https://en.wikipedia.org/wiki/Kolkata_Knight_Riders` and look for season tables, OR manually construct the JSON from the known-correct data in the research document
- Log: "WARNING: iplt20.com scrape returned insufficient data. Manual fallback required — see research document for known correct values."

If scrape-top-performers.js produces empty arrays (ESPNcricinfo blocked), construct fallback JSON manually using the values from the research file's "Known Data Inaccuracies" table. The JSON format must match the raw output format: `{ rows: [{ cells: string[] }] }` with cells in the order: [rank, player, matches, innings, runs, ...].

Write a brief summary to console:
- Season records: N rows scraped (expected: ~18 rows for 2008-2025)
- Batting stats: N rows scraped (expected: 10+ rows)
- Bowling stats: N rows scraped (expected: 10+ rows)
  </action>
  <verify>
    <automated>cd /Users/mithra_sundaram/Desktop/code/AI/projects/team_site && node -e "const fs=require('fs'); ['scripts/scraped-season-records.json','scripts/scraped-top-performers-batting.json','scripts/scraped-top-performers-bowling.json'].forEach(f => { if(!fs.existsSync(f)) throw new Error('Missing: '+f); const d=JSON.parse(fs.readFileSync(f,'utf8')); console.log(f, 'exists, size:', JSON.stringify(d).length, 'bytes'); })"</automated>
  </verify>
  <done>All three JSON files exist and contain non-empty content. Console output shows row counts for each scrape.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Human review of scraped JSON data before applying corrections</name>
  <action>Present the three scraped JSON files to the user for manual verification against Wikipedia sources. The user must confirm or correct data values before Plan 04 applies them to stats.ts.</action>
  <what-built>
    Three JSON files containing raw scraped data:
    - scripts/scraped-season-records.json — KKR season-by-season records (raw table rows from iplt20.com or Wikipedia fallback)
    - scripts/scraped-top-performers-batting.json — KKR top run-scorers (raw table rows from ESPNcricinfo)
    - scripts/scraped-top-performers-bowling.json — KKR top wicket-takers (raw table rows from ESPNcricinfo)
  </what-built>
  <how-to-verify>
    1. Open scripts/scraped-season-records.json in your editor
       - Confirm there are rows covering 2008-2025 (18 seasons)
       - Find 2021 row — verify it shows KKR as runners-up (position 2), not position 6
       - Find 2025 row — verify it exists with position 8 (or note if missing)
       - Cross-reference against: https://en.wikipedia.org/wiki/Kolkata_Knight_Riders#Seasons

    2. Open scripts/scraped-top-performers-batting.json
       - Check Sunil Narine's run total — should be ~1507 (not 3500 as currently in stats.ts)
       - Check Robin Uthappa — should be ~2649 KKR runs (not 3145)
       - Check Gautam Gambhir — should be in the 3035-3345 range
       - Cross-reference: https://en.wikipedia.org/wiki/Kolkata_Knight_Riders#Records_and_statistics

    3. Open scripts/scraped-top-performers-bowling.json
       - Check Sunil Narine wickets — should be around 178 (KKR-specific) or ~192 total IPL
       - Verify other bowlers (Umesh Yadav, Andre Russell, Kuldeep Yadav, Varun Chakravarthy) have plausible KKR wicket counts

    4. If any values look wrong (e.g., career totals vs KKR-only totals), note the correct values for each player in your reply

    Known corrections REQUIRED regardless of scrape output:
    - 2021: position must be 2 (runners-up), not 6
    - 2025: season entry must be added (position 8, ~5 wins, ~9 losses)
    - Sunil Narine runs: must be corrected from 3500 to accurate KKR-specific value
  </how-to-verify>
  <resume-signal>Type "approved" if the scraped data looks accurate and complete, OR describe specific corrections needed for each field that needs fixing (e.g. "2021 position should be 2, Narine runs should be 1507, 2025 add: wins=5 losses=9 position=8")</resume-signal>
</task>

</tasks>

<verification>
1. All three scraped JSON files exist and are non-empty
2. Human has reviewed and approved (or corrected) the data
3. Known errors confirmed: 2021 position=6 flagged as wrong (should be 2), 2025 season missing/to be added
4. Top performer corrections identified from scraped data
</verification>

<success_criteria>
Human has reviewed the raw scraped JSON and provided either "approved" (data is accurate as-is) or specific field corrections. Plan 04 has the verified values it needs to update stats.ts with confidence.
</success_criteria>

<output>
After completion, create `.planning/phases/05-data-accuracy-and-real-assets/05-02-SUMMARY.md`

Include in SUMMARY: the verified corrections list (exact field values confirmed by human review) so Plan 04 can apply them without ambiguity.
</output>
